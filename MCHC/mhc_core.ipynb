{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711fe0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m new project at `C:\\Users\\79021\\AppData\\Local\\Temp\\jl_fEUt6v`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\79021\\.julia\\registries\\General.toml`\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\79021\\AppData\\Local\\Temp\\jl_fEUt6v\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\79021\\AppData\\Local\\Temp\\jl_fEUt6v\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_xkbcomp_jll ───────────── v1.4.7+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m libdecor_jll ───────────────── v0.2.2+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GR_jll ─────────────────────── v0.73.19+1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_xcb_util_wm_jll ───────── v0.4.2+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Measures ───────────────────── v0.3.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ConcurrentUtilities ────────── v2.5.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LoggingExtras ──────────────── v1.2.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GR ─────────────────────────── v0.73.19\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_xcb_util_image_jll ────── v0.4.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_libSM_jll ─────────────── v1.2.6+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_xcb_util_jll ──────────── v0.4.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RecipesPipeline ────────────── v0.6.12\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OpenSSL ────────────────────── v1.6.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HTTP ───────────────────────── v1.10.19\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_libxkbfile_jll ────────── v1.1.3+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_libXinerama_jll ───────── v1.1.6+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m EpollShim_jll ──────────────── v0.0.20230411+1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JSON ───────────────────────── v1.4.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m xkbcommon_jll ──────────────── v1.13.0+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_xcb_util_keysyms_jll ──── v0.4.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SimpleBufferStream ─────────── v1.2.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PlotThemes ─────────────────── v3.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m fzf_jll ────────────────────── v0.61.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MbedTLS ────────────────────── v1.1.9\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GLFW_jll ───────────────────── v3.4.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JLFzf ──────────────────────── v0.1.11\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m libpng_jll ─────────────────── v1.6.54+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m mtdev_jll ──────────────────── v1.1.7+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CodecZlib ──────────────────── v0.7.8\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ExceptionUnwrapping ────────── v0.1.11\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Dbus_jll ───────────────────── v1.16.2+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m eudev_jll ──────────────────── v3.2.14+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_xcb_util_cursor_jll ───── v0.1.6+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Plots ──────────────────────── v1.41.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m libevdev_jll ───────────────── v1.13.4+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Vulkan_Loader_jll ──────────── v1.3.243+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m libinput_jll ───────────────── v1.28.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_libXi_jll ─────────────── v1.8.3+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Qt6ShaderTools_jll ─────────── v6.8.2+1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Ghostscript_jll ────────────── v9.55.1+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Qt6Declarative_jll ─────────── v6.8.2+1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MbedTLS_jll ────────────────── v2.28.1010+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_libXcursor_jll ────────── v1.2.4+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Wayland_jll ────────────────── v1.24.0+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_xcb_util_renderutil_jll ─ v0.3.10+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_libICE_jll ────────────── v1.1.2+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Latexify ───────────────────── v0.16.10\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_libXrandr_jll ─────────── v1.5.5+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_xkeyboard_config_jll ──── v2.44.0+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BitFlags ───────────────────── v0.1.9\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Xorg_libXfixes_jll ─────────── v6.0.2+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Qt6Wayland_jll ─────────────── v6.8.2+2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Qt6Base_jll ────────────────── v6.8.2+2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Unzip ──────────────────────── v0.2.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m URIs ───────────────────────── v1.6.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StructUtils ────────────────── v2.6.2\n",
      "\u001b[32m\u001b[1m  Installing\u001b[22m\u001b[39m 1 artifacts\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m artifact libpng                494.2 KiB\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\79021\\AppData\\Local\\Temp\\jl_fEUt6v\\Project.toml`\n",
      "  \u001b[90m[587475ba] \u001b[39m\u001b[92m+ Flux v0.16.7\u001b[39m\n",
      "  \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.41.4\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra v1.12.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\79021\\AppData\\Local\\Temp\\jl_fEUt6v\\Manifest.toml`\n",
      "  \u001b[90m[621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.5.0\u001b[39m\n",
      "  \u001b[90m[7d9f7c33] \u001b[39m\u001b[92m+ Accessors v0.1.43\u001b[39m\n",
      "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.4.0\u001b[39m\n",
      "  \u001b[90m[66dad0bd] \u001b[39m\u001b[92m+ AliasTables v1.1.3\u001b[39m\n",
      "  \u001b[90m[dce04be8] \u001b[39m\u001b[92m+ ArgCheck v2.5.0\u001b[39m\n",
      "  \u001b[90m[a9b6321e] \u001b[39m\u001b[92m+ Atomix v1.1.2\u001b[39m\n",
      "  \u001b[90m[198e06fe] \u001b[39m\u001b[92m+ BangBang v0.4.6\u001b[39m\n",
      "  \u001b[90m[9718e550] \u001b[39m\u001b[92m+ Baselet v0.1.1\u001b[39m\n",
      "  \u001b[90m[d1d4a3ce] \u001b[39m\u001b[92m+ BitFlags v0.1.9\u001b[39m\n",
      "  \u001b[90m[082447d4] \u001b[39m\u001b[92m+ ChainRules v1.72.6\u001b[39m\n",
      "  \u001b[90m[d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.26.0\u001b[39m\n",
      "  \u001b[90m[944b1d66] \u001b[39m\u001b[92m+ CodecZlib v0.7.8\u001b[39m\n",
      "  \u001b[90m[35d6a980] \u001b[39m\u001b[92m+ ColorSchemes v3.31.0\u001b[39m\n",
      "  \u001b[90m[3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.12.1\u001b[39m\n",
      "  \u001b[90m[c3611d14] \u001b[39m\u001b[92m+ ColorVectorSpace v0.11.0\u001b[39m\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.1\u001b[39m\n",
      "  \u001b[90m[bbf7d656] \u001b[39m\u001b[92m+ CommonSubexpressions v0.3.1\u001b[39m\n",
      "  \u001b[90m[34da2185] \u001b[39m\u001b[92m+ Compat v4.18.1\u001b[39m\n",
      "  \u001b[90m[a33af91c] \u001b[39m\u001b[92m+ CompositionsBase v0.1.2\u001b[39m\n",
      "  \u001b[90m[f0e56b4a] \u001b[39m\u001b[92m+ ConcurrentUtilities v2.5.0\u001b[39m\n",
      "  \u001b[90m[187b0558] \u001b[39m\u001b[92m+ ConstructionBase v1.6.0\u001b[39m\n",
      "  \u001b[90m[6add18c4] \u001b[39m\u001b[92m+ ContextVariablesX v0.1.3\u001b[39m\n",
      "  \u001b[90m[d38c429a] \u001b[39m\u001b[92m+ Contour v0.6.3\u001b[39m\n",
      "  \u001b[90m[9a962f9c] \u001b[39m\u001b[92m+ DataAPI v1.16.0\u001b[39m\n",
      "  \u001b[90m[864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.19.3\u001b[39m\n",
      "  \u001b[90m[e2d170a0] \u001b[39m\u001b[92m+ DataValueInterfaces v1.0.0\u001b[39m\n",
      "  \u001b[90m[244e2a9f] \u001b[39m\u001b[92m+ DefineSingletons v0.1.2\u001b[39m\n",
      "  \u001b[90m[8bb1440f] \u001b[39m\u001b[92m+ DelimitedFiles v1.9.1\u001b[39m\n",
      "  \u001b[90m[163ba53b] \u001b[39m\u001b[92m+ DiffResults v1.1.0\u001b[39m\n",
      "  \u001b[90m[b552c78f] \u001b[39m\u001b[92m+ DiffRules v1.15.1\u001b[39m\n",
      "  \u001b[90m[ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.9.5\u001b[39m\n",
      "  \u001b[90m[f151be2c] \u001b[39m\u001b[92m+ EnzymeCore v0.8.18\u001b[39m\n",
      "  \u001b[90m[460bff9d] \u001b[39m\u001b[92m+ ExceptionUnwrapping v0.1.11\u001b[39m\n",
      "  \u001b[90m[c87230d0] \u001b[39m\u001b[92m+ FFMPEG v0.4.5\u001b[39m\n",
      "  \u001b[90m[cc61a311] \u001b[39m\u001b[92m+ FLoops v0.2.2\u001b[39m\n",
      "  \u001b[90m[b9860ae5] \u001b[39m\u001b[92m+ FLoopsBase v0.1.1\u001b[39m\n",
      "  \u001b[90m[1a297f60] \u001b[39m\u001b[92m+ FillArrays v1.15.0\u001b[39m\n",
      "  \u001b[90m[53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.5\u001b[39m\n",
      "  \u001b[90m[587475ba] \u001b[39m\u001b[92m+ Flux v0.16.7\u001b[39m\n",
      "  \u001b[90m[1fa38f19] \u001b[39m\u001b[92m+ Format v1.3.7\u001b[39m\n",
      "  \u001b[90m[f6369f11] \u001b[39m\u001b[92m+ ForwardDiff v1.3.1\u001b[39m\n",
      "  \u001b[90m[d9f16b24] \u001b[39m\u001b[92m+ Functors v0.5.2\u001b[39m\n",
      "  \u001b[90m[46192b85] \u001b[39m\u001b[92m+ GPUArraysCore v0.2.0\u001b[39m\n",
      "  \u001b[90m[28b8d3ca] \u001b[39m\u001b[92m+ GR v0.73.19\u001b[39m\n",
      "  \u001b[90m[42e2da0e] \u001b[39m\u001b[92m+ Grisu v1.0.2\u001b[39m\n",
      "  \u001b[90m[cd3eb016] \u001b[39m\u001b[92m+ HTTP v1.10.19\u001b[39m\n",
      "  \u001b[90m[076d061b] \u001b[39m\u001b[92m+ HashArrayMappedTries v0.2.0\u001b[39m\n",
      "  \u001b[90m[7869d1d1] \u001b[39m\u001b[92m+ IRTools v0.4.15\u001b[39m\n",
      "  \u001b[90m[22cec73e] \u001b[39m\u001b[92m+ InitialValues v0.3.1\u001b[39m\n",
      "  \u001b[90m[3587e190] \u001b[39m\u001b[92m+ InverseFunctions v0.1.17\u001b[39m\n",
      "  \u001b[90m[92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.2.6\u001b[39m\n",
      "  \u001b[90m[82899510] \u001b[39m\u001b[92m+ IteratorInterfaceExtensions v1.0.0\u001b[39m\n",
      "  \u001b[90m[1019f520] \u001b[39m\u001b[92m+ JLFzf v0.1.11\u001b[39m\n",
      "  \u001b[90m[692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.7.1\u001b[39m\n",
      "  \u001b[90m[682c06a0] \u001b[39m\u001b[92m+ JSON v1.4.0\u001b[39m\n",
      "  \u001b[90m[b14d175d] \u001b[39m\u001b[92m+ JuliaVariables v0.2.4\u001b[39m\n",
      "  \u001b[90m[63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.39\u001b[39m\n",
      "  \u001b[90m[b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.4.0\u001b[39m\n",
      "  \u001b[90m[23fbe1c1] \u001b[39m\u001b[92m+ Latexify v0.16.10\u001b[39m\n",
      "  \u001b[90m[2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.29\u001b[39m\n",
      "  \u001b[90m[e6f89c97] \u001b[39m\u001b[92m+ LoggingExtras v1.2.0\u001b[39m\n",
      "  \u001b[90m[c2834f40] \u001b[39m\u001b[92m+ MLCore v1.0.0\u001b[39m\n",
      "  \u001b[90m[7e8f7934] \u001b[39m\u001b[92m+ MLDataDevices v1.17.1\u001b[39m\n",
      "  \u001b[90m[d8e11817] \u001b[39m\u001b[92m+ MLStyle v0.4.17\u001b[39m\n",
      "  \u001b[90m[f1d291b0] \u001b[39m\u001b[92m+ MLUtils v0.4.8\u001b[39m\n",
      "  \u001b[90m[1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.16\u001b[39m\n",
      "  \u001b[90m[739be429] \u001b[39m\u001b[92m+ MbedTLS v1.1.9\u001b[39m\n",
      "  \u001b[90m[442fdcdd] \u001b[39m\u001b[92m+ Measures v0.3.3\u001b[39m\n",
      "  \u001b[90m[128add7d] \u001b[39m\u001b[92m+ MicroCollections v0.2.0\u001b[39m\n",
      "  \u001b[90m[e1d29d7a] \u001b[39m\u001b[92m+ Missings v1.2.0\u001b[39m\n",
      "  \u001b[90m[872c559c] \u001b[39m\u001b[92m+ NNlib v0.9.33\u001b[39m\n",
      "  \u001b[90m[77ba4419] \u001b[39m\u001b[92m+ NaNMath v1.1.3\u001b[39m\n",
      "  \u001b[90m[71a1bf82] \u001b[39m\u001b[92m+ NameResolution v0.1.5\u001b[39m\n",
      "  \u001b[90m[0b1bfda6] \u001b[39m\u001b[92m+ OneHotArrays v0.2.10\u001b[39m\n",
      "  \u001b[90m[4d8831e6] \u001b[39m\u001b[92m+ OpenSSL v1.6.1\u001b[39m\n",
      "  \u001b[90m[3bd65402] \u001b[39m\u001b[92m+ Optimisers v0.4.7\u001b[39m\n",
      "  \u001b[90m[bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.8.1\u001b[39m\n",
      "  \u001b[90m[69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.3\u001b[39m\n",
      "  \u001b[90m[ccf2f8ad] \u001b[39m\u001b[92m+ PlotThemes v3.3.0\u001b[39m\n",
      "  \u001b[90m[995b91a9] \u001b[39m\u001b[92m+ PlotUtils v1.4.4\u001b[39m\n",
      "  \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.41.4\u001b[39m\n",
      "  \u001b[90m[aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.3.3\u001b[39m\n",
      "  \u001b[90m[21216c6a] \u001b[39m\u001b[92m+ Preferences v1.5.1\u001b[39m\n",
      "  \u001b[90m[8162dcfd] \u001b[39m\u001b[92m+ PrettyPrint v0.2.0\u001b[39m\n",
      "  \u001b[90m[33c8b6b6] \u001b[39m\u001b[92m+ ProgressLogging v0.1.6\u001b[39m\n",
      "  \u001b[90m[43287f4e] \u001b[39m\u001b[92m+ PtrArrays v1.3.0\u001b[39m\n",
      "  \u001b[90m[c1ae055f] \u001b[39m\u001b[92m+ RealDot v0.1.0\u001b[39m\n",
      "  \u001b[90m[3cdcf5f2] \u001b[39m\u001b[92m+ RecipesBase v1.3.4\u001b[39m\n",
      "  \u001b[90m[01d81517] \u001b[39m\u001b[92m+ RecipesPipeline v0.6.12\u001b[39m\n",
      "  \u001b[90m[189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
      "  \u001b[90m[05181044] \u001b[39m\u001b[92m+ RelocatableFolders v1.0.1\u001b[39m\n",
      "  \u001b[90m[ae029012] \u001b[39m\u001b[92m+ Requires v1.3.1\u001b[39m\n",
      "  \u001b[90m[431bcebd] \u001b[39m\u001b[92m+ SciMLPublic v1.0.1\u001b[39m\n",
      "  \u001b[90m[7e506255] \u001b[39m\u001b[92m+ ScopedValues v1.5.0\u001b[39m\n",
      "  \u001b[90m[6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.3.0\u001b[39m\n",
      "  \u001b[90m[efcf1570] \u001b[39m\u001b[92m+ Setfield v1.1.2\u001b[39m\n",
      "  \u001b[90m[605ecd9f] \u001b[39m\u001b[92m+ ShowCases v0.1.0\u001b[39m\n",
      "  \u001b[90m[992d4aef] \u001b[39m\u001b[92m+ Showoff v1.0.3\u001b[39m\n",
      "  \u001b[90m[777ac1f9] \u001b[39m\u001b[92m+ SimpleBufferStream v1.2.0\u001b[39m\n",
      "  \u001b[90m[699a6c99] \u001b[39m\u001b[92m+ SimpleTraits v0.9.5\u001b[39m\n",
      "  \u001b[90m[a2af1166] \u001b[39m\u001b[92m+ SortingAlgorithms v1.2.2\u001b[39m\n",
      "  \u001b[90m[dc90abb0] \u001b[39m\u001b[92m+ SparseInverseSubset v0.1.2\u001b[39m\n",
      "  \u001b[90m[276daf66] \u001b[39m\u001b[92m+ SpecialFunctions v2.6.1\u001b[39m\n",
      "  \u001b[90m[171d559e] \u001b[39m\u001b[92m+ SplittablesBase v0.1.15\u001b[39m\n",
      "  \u001b[90m[860ef19b] \u001b[39m\u001b[92m+ StableRNGs v1.0.4\u001b[39m\n",
      "  \u001b[90m[90137ffa] \u001b[39m\u001b[92m+ StaticArrays v1.9.16\u001b[39m\n",
      "  \u001b[90m[1e83bf80] \u001b[39m\u001b[92m+ StaticArraysCore v1.4.4\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[82ae8749] \u001b[39m\u001b[92m+ StatsAPI v1.8.0\u001b[39m\n",
      "  \u001b[90m[2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.10\u001b[39m\n",
      "  \u001b[90m[09ab397b] \u001b[39m\u001b[92m+ StructArrays v0.7.2\u001b[39m\n",
      "  \u001b[90m[ec057cc2] \u001b[39m\u001b[92m+ StructUtils v2.6.2\u001b[39m\n",
      "  \u001b[90m[3783bdb8] \u001b[39m\u001b[92m+ TableTraits v1.0.1\u001b[39m\n",
      "  \u001b[90m[bd369af6] \u001b[39m\u001b[92m+ Tables v1.12.1\u001b[39m\n",
      "  \u001b[90m[62fd8b95] \u001b[39m\u001b[92m+ TensorCore v0.1.1\u001b[39m\n",
      "  \u001b[90m[3bb67fe8] \u001b[39m\u001b[92m+ TranscodingStreams v0.11.3\u001b[39m\n",
      "  \u001b[90m[28d57a85] \u001b[39m\u001b[92m+ Transducers v0.4.85\u001b[39m\n",
      "  \u001b[90m[5c2747f8] \u001b[39m\u001b[92m+ URIs v1.6.1\u001b[39m\n",
      "  \u001b[90m[1cfade01] \u001b[39m\u001b[92m+ UnicodeFun v0.4.1\u001b[39m\n",
      "  \u001b[90m[013be700] \u001b[39m\u001b[92m+ UnsafeAtomics v0.3.0\u001b[39m\n",
      "  \u001b[90m[41fe7b60] \u001b[39m\u001b[92m+ Unzip v0.2.0\u001b[39m\n",
      "  \u001b[90m[e88e6eb3] \u001b[39m\u001b[92m+ Zygote v0.7.10\u001b[39m\n",
      "  \u001b[90m[700de1a5] \u001b[39m\u001b[92m+ ZygoteRules v0.2.7\u001b[39m\n",
      "  \u001b[90m[6e34b625] \u001b[39m\u001b[92m+ Bzip2_jll v1.0.9+0\u001b[39m\n",
      "  \u001b[90m[83423d85] \u001b[39m\u001b[92m+ Cairo_jll v1.18.5+0\u001b[39m\n",
      "  \u001b[90m[ee1fde0b] \u001b[39m\u001b[92m+ Dbus_jll v1.16.2+0\u001b[39m\n",
      "  \u001b[90m[2702e6a9] \u001b[39m\u001b[92m+ EpollShim_jll v0.0.20230411+1\u001b[39m\n",
      "  \u001b[90m[2e619515] \u001b[39m\u001b[92m+ Expat_jll v2.7.3+0\u001b[39m\n",
      "  \u001b[90m[b22a6f82] \u001b[39m\u001b[92m+ FFMPEG_jll v8.0.1+0\u001b[39m\n",
      "  \u001b[90m[a3f928ae] \u001b[39m\u001b[92m+ Fontconfig_jll v2.17.1+0\u001b[39m\n",
      "  \u001b[90m[d7e528f0] \u001b[39m\u001b[92m+ FreeType2_jll v2.13.4+0\u001b[39m\n",
      "  \u001b[90m[559328eb] \u001b[39m\u001b[92m+ FriBidi_jll v1.0.17+0\u001b[39m\n",
      "  \u001b[90m[0656b61e] \u001b[39m\u001b[92m+ GLFW_jll v3.4.1+0\u001b[39m\n",
      "  \u001b[90m[d2c73de3] \u001b[39m\u001b[92m+ GR_jll v0.73.19+1\u001b[39m\n",
      "  \u001b[90m[b0724c58] \u001b[39m\u001b[92m+ GettextRuntime_jll v0.22.4+0\u001b[39m\n",
      "  \u001b[90m[61579ee1] \u001b[39m\u001b[92m+ Ghostscript_jll v9.55.1+0\u001b[39m\n",
      "  \u001b[90m[7746bdde] \u001b[39m\u001b[92m+ Glib_jll v2.86.2+0\u001b[39m\n",
      "  \u001b[90m[3b182d85] \u001b[39m\u001b[92m+ Graphite2_jll v1.3.15+0\u001b[39m\n",
      "  \u001b[90m[2e76f6c2] \u001b[39m\u001b[92m+ HarfBuzz_jll v8.5.1+0\u001b[39m\n",
      "  \u001b[90m[aacddb02] \u001b[39m\u001b[92m+ JpegTurbo_jll v3.1.4+0\u001b[39m\n",
      "  \u001b[90m[c1c5ebd0] \u001b[39m\u001b[92m+ LAME_jll v3.100.3+0\u001b[39m\n",
      "  \u001b[90m[88015f11] \u001b[39m\u001b[92m+ LERC_jll v4.0.1+0\u001b[39m\n",
      "  \u001b[90m[1d63c593] \u001b[39m\u001b[92m+ LLVMOpenMP_jll v18.1.8+0\u001b[39m\n",
      "  \u001b[90m[dd4b983a] \u001b[39m\u001b[92m+ LZO_jll v2.10.3+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[e9f186c6] \u001b[39m\u001b[92m+ Libffi_jll v3.4.7+0\u001b[39m\n",
      "  \u001b[90m[7e76a0d4] \u001b[39m\u001b[92m+ Libglvnd_jll v1.7.1+1\u001b[39m\n",
      "  \u001b[90m[94ce4f54] \u001b[39m\u001b[92m+ Libiconv_jll v1.18.0+0\u001b[39m\n",
      "  \u001b[90m[4b2f31a3] \u001b[39m\u001b[92m+ Libmount_jll v2.41.2+0\u001b[39m\n",
      "  \u001b[90m[89763e89] \u001b[39m\u001b[92m+ Libtiff_jll v4.7.2+0\u001b[39m\n",
      "  \u001b[90m[38a345b3] \u001b[39m\u001b[92m+ Libuuid_jll v2.41.2+0\u001b[39m\n",
      "  \u001b[90m[c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.1010+0\u001b[39m\n",
      "  \u001b[90m[e7412a2a] \u001b[39m\u001b[92m+ Ogg_jll v1.3.6+0\u001b[39m\n",
      "  \u001b[90m[efe28fd5] \u001b[39m\u001b[92m+ OpenSpecFun_jll v0.5.6+0\u001b[39m\n",
      "  \u001b[90m[91d4177d] \u001b[39m\u001b[92m+ Opus_jll v1.6.0+0\u001b[39m\n",
      "  \u001b[90m[36c8627f] \u001b[39m\u001b[92m+ Pango_jll v1.57.0+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[30392449] \u001b[39m\u001b[92m+ Pixman_jll v0.44.2+0\u001b[39m\n",
      "  \u001b[90m[c0090381] \u001b[39m\u001b[92m+ Qt6Base_jll v6.8.2+2\u001b[39m\n",
      "  \u001b[90m[629bc702] \u001b[39m\u001b[92m+ Qt6Declarative_jll v6.8.2+1\u001b[39m\n",
      "  \u001b[90m[ce943373] \u001b[39m\u001b[92m+ Qt6ShaderTools_jll v6.8.2+1\u001b[39m\n",
      "  \u001b[90m[e99dba38] \u001b[39m\u001b[92m+ Qt6Wayland_jll v6.8.2+2\u001b[39m\n",
      "  \u001b[90m[a44049a8] \u001b[39m\u001b[92m+ Vulkan_Loader_jll v1.3.243+0\u001b[39m\n",
      "  \u001b[90m[a2964d1f] \u001b[39m\u001b[92m+ Wayland_jll v1.24.0+0\u001b[39m\n",
      "  \u001b[90m[ffd25f8a] \u001b[39m\u001b[92m+ XZ_jll v5.8.2+0\u001b[39m\n",
      "  \u001b[90m[f67eecfb] \u001b[39m\u001b[92m+ Xorg_libICE_jll v1.1.2+0\u001b[39m\n",
      "  \u001b[90m[c834827a] \u001b[39m\u001b[92m+ Xorg_libSM_jll v1.2.6+0\u001b[39m\n",
      "  \u001b[90m[4f6342f7] \u001b[39m\u001b[92m+ Xorg_libX11_jll v1.8.12+0\u001b[39m\n",
      "  \u001b[90m[0c0b7dd1] \u001b[39m\u001b[92m+ Xorg_libXau_jll v1.0.13+0\u001b[39m\n",
      "  \u001b[90m[935fb764] \u001b[39m\u001b[92m+ Xorg_libXcursor_jll v1.2.4+0\u001b[39m\n",
      "  \u001b[90m[a3789734] \u001b[39m\u001b[92m+ Xorg_libXdmcp_jll v1.1.6+0\u001b[39m\n",
      "  \u001b[90m[1082639a] \u001b[39m\u001b[92m+ Xorg_libXext_jll v1.3.7+0\u001b[39m\n",
      "  \u001b[90m[d091e8ba] \u001b[39m\u001b[92m+ Xorg_libXfixes_jll v6.0.2+0\u001b[39m\n",
      "  \u001b[90m[a51aa0fd] \u001b[39m\u001b[92m+ Xorg_libXi_jll v1.8.3+0\u001b[39m\n",
      "  \u001b[90m[d1454406] \u001b[39m\u001b[92m+ Xorg_libXinerama_jll v1.1.6+0\u001b[39m\n",
      "  \u001b[90m[ec84b674] \u001b[39m\u001b[92m+ Xorg_libXrandr_jll v1.5.5+0\u001b[39m\n",
      "  \u001b[90m[ea2f1a96] \u001b[39m\u001b[92m+ Xorg_libXrender_jll v0.9.12+0\u001b[39m\n",
      "  \u001b[90m[c7cfdc94] \u001b[39m\u001b[92m+ Xorg_libxcb_jll v1.17.1+0\u001b[39m\n",
      "  \u001b[90m[cc61e674] \u001b[39m\u001b[92m+ Xorg_libxkbfile_jll v1.1.3+0\u001b[39m\n",
      "  \u001b[90m[e920d4aa] \u001b[39m\u001b[92m+ Xorg_xcb_util_cursor_jll v0.1.6+0\u001b[39m\n",
      "  \u001b[90m[12413925] \u001b[39m\u001b[92m+ Xorg_xcb_util_image_jll v0.4.1+0\u001b[39m\n",
      "  \u001b[90m[2def613f] \u001b[39m\u001b[92m+ Xorg_xcb_util_jll v0.4.1+0\u001b[39m\n",
      "  \u001b[90m[975044d2] \u001b[39m\u001b[92m+ Xorg_xcb_util_keysyms_jll v0.4.1+0\u001b[39m\n",
      "  \u001b[90m[0d47668e] \u001b[39m\u001b[92m+ Xorg_xcb_util_renderutil_jll v0.3.10+0\u001b[39m\n",
      "  \u001b[90m[c22f9ab0] \u001b[39m\u001b[92m+ Xorg_xcb_util_wm_jll v0.4.2+0\u001b[39m\n",
      "  \u001b[90m[35661453] \u001b[39m\u001b[92m+ Xorg_xkbcomp_jll v1.4.7+0\u001b[39m\n",
      "  \u001b[90m[33bec58e] \u001b[39m\u001b[92m+ Xorg_xkeyboard_config_jll v2.44.0+0\u001b[39m\n",
      "  \u001b[90m[c5fb5394] \u001b[39m\u001b[92m+ Xorg_xtrans_jll v1.6.0+0\u001b[39m\n",
      "  \u001b[90m[3161d3a3] \u001b[39m\u001b[92m+ Zstd_jll v1.5.7+1\u001b[39m\n",
      "  \u001b[90m[35ca27e7] \u001b[39m\u001b[92m+ eudev_jll v3.2.14+0\u001b[39m\n",
      "  \u001b[90m[214eeab7] \u001b[39m\u001b[92m+ fzf_jll v0.61.1+0\u001b[39m\n",
      "  \u001b[90m[a4ae2306] \u001b[39m\u001b[92m+ libaom_jll v3.13.1+0\u001b[39m\n",
      "  \u001b[90m[0ac62f75] \u001b[39m\u001b[92m+ libass_jll v0.17.4+0\u001b[39m\n",
      "  \u001b[90m[1183f4f0] \u001b[39m\u001b[92m+ libdecor_jll v0.2.2+0\u001b[39m\n",
      "  \u001b[90m[2db6ffa8] \u001b[39m\u001b[92m+ libevdev_jll v1.13.4+0\u001b[39m\n",
      "  \u001b[90m[f638f0a6] \u001b[39m\u001b[92m+ libfdk_aac_jll v2.0.4+0\u001b[39m\n",
      "  \u001b[90m[36db933b] \u001b[39m\u001b[92m+ libinput_jll v1.28.1+0\u001b[39m\n",
      "  \u001b[90m[b53b4c65] \u001b[39m\u001b[92m+ libpng_jll v1.6.54+0\u001b[39m\n",
      "  \u001b[90m[f27f6e37] \u001b[39m\u001b[92m+ libvorbis_jll v1.3.8+0\u001b[39m\n",
      "  \u001b[90m[009596ad] \u001b[39m\u001b[92m+ mtdev_jll v1.1.7+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[1270edf5] \u001b[39m\u001b[92m+ x264_jll v10164.0.1+0\u001b[39m\n",
      "  \u001b[90m[dfaa095f] \u001b[39m\u001b[92m+ x265_jll v4.1.0+0\u001b[39m\n",
      "  \u001b[90m[d8fb68d0] \u001b[39m\u001b[92m+ xkbcommon_jll v1.13.0+0\u001b[39m\n",
      "  \u001b[90m[0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.2\u001b[39m\n",
      "  \u001b[90m[56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[2a0f44e3] \u001b[39m\u001b[92m+ Base64 v1.11.0\u001b[39m\n",
      "  \u001b[90m[ade2ca70] \u001b[39m\u001b[92m+ Dates v1.11.0\u001b[39m\n",
      "  \u001b[90m[8ba89e20] \u001b[39m\u001b[92m+ Distributed v1.11.0\u001b[39m\n",
      "  \u001b[90m[f43a241f] \u001b[39m\u001b[92m+ Downloads v1.7.0\u001b[39m\n",
      "  \u001b[90m[7b1f6079] \u001b[39m\u001b[92m+ FileWatching v1.11.0\u001b[39m\n",
      "  \u001b[90m[9fa8497b] \u001b[39m\u001b[92m+ Future v1.11.0\u001b[39m\n",
      "  \u001b[90m[b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils v1.11.0\u001b[39m\n",
      "  \u001b[90m[ac6e5ff7] \u001b[39m\u001b[92m+ JuliaSyntaxHighlighting v1.12.0\u001b[39m\n",
      "  \u001b[90m[b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.4\u001b[39m\n",
      "  \u001b[90m[76f85450] \u001b[39m\u001b[92m+ LibGit2 v1.11.0\u001b[39m\n",
      "  \u001b[90m[8f399da3] \u001b[39m\u001b[92m+ Libdl v1.11.0\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra v1.12.0\u001b[39m\n",
      "  \u001b[90m[56ddb016] \u001b[39m\u001b[92m+ Logging v1.11.0\u001b[39m\n",
      "  \u001b[90m[d6f4376e] \u001b[39m\u001b[92m+ Markdown v1.11.0\u001b[39m\n",
      "  \u001b[90m[a63ad114] \u001b[39m\u001b[92m+ Mmap v1.11.0\u001b[39m\n",
      "  \u001b[90m[ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.3.0\u001b[39m\n",
      "  \u001b[90m[44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.12.1\u001b[39m\n",
      "  \u001b[90m[de0858da] \u001b[39m\u001b[92m+ Printf v1.11.0\u001b[39m\n",
      "  \u001b[90m[3fa0cd96] \u001b[39m\u001b[92m+ REPL v1.11.0\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[92m+ Random v1.11.0\u001b[39m\n",
      "  \u001b[90m[ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
      "  \u001b[90m[9e88b42a] \u001b[39m\u001b[92m+ Serialization v1.11.0\u001b[39m\n",
      "  \u001b[90m[6462fe0b] \u001b[39m\u001b[92m+ Sockets v1.11.0\u001b[39m\n",
      "  \u001b[90m[2f01184e] \u001b[39m\u001b[92m+ SparseArrays v1.12.0\u001b[39m\n",
      "  \u001b[90m[f489334b] \u001b[39m\u001b[92m+ StyledStrings v1.11.0\u001b[39m\n",
      "  \u001b[90m[4607b0f0] \u001b[39m\u001b[92m+ SuiteSparse\u001b[39m\n",
      "  \u001b[90m[fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.3\u001b[39m\n",
      "  \u001b[90m[a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.0\u001b[39m\n",
      "  \u001b[90m[8dfed614] \u001b[39m\u001b[92m+ Test v1.11.0\u001b[39m\n",
      "  \u001b[90m[cf7118a7] \u001b[39m\u001b[92m+ UUIDs v1.11.0\u001b[39m\n",
      "  \u001b[90m[4ec0a83e] \u001b[39m\u001b[92m+ Unicode v1.11.0\u001b[39m\n",
      "  \u001b[90m[e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.3.0+1\u001b[39m\n",
      "  \u001b[90m[deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v8.15.0+0\u001b[39m\n",
      "  \u001b[90m[e37daf67] \u001b[39m\u001b[92m+ LibGit2_jll v1.9.0+0\u001b[39m\n",
      "  \u001b[90m[29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.11.3+1\u001b[39m\n",
      "  \u001b[90m[14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2025.5.20\u001b[39m\n",
      "  \u001b[90m[4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.29+0\u001b[39m\n",
      "  \u001b[90m[05823500] \u001b[39m\u001b[92m+ OpenLibm_jll v0.8.7+0\u001b[39m\n",
      "  \u001b[90m[458c3c95] \u001b[39m\u001b[92m+ OpenSSL_jll v3.5.4+0\u001b[39m\n",
      "  \u001b[90m[efcefdf7] \u001b[39m\u001b[92m+ PCRE2_jll v10.44.0+1\u001b[39m\n",
      "  \u001b[90m[bea87d4a] \u001b[39m\u001b[92m+ SuiteSparse_jll v7.8.3+2\u001b[39m\n",
      "  \u001b[90m[83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.3.1+2\u001b[39m\n",
      "  \u001b[90m[8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.15.0+0\u001b[39m\n",
      "  \u001b[90m[8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.64.0+1\u001b[39m\n",
      "  \u001b[90m[3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.7.0+0\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m packages...\n",
      "   1262.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibpng_jll\u001b[39m\n",
      "   2097.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStructUtils\u001b[39m\n",
      "    583.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStructUtils → StructUtilsTablesExt\u001b[39m\n",
      "   1890.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mZygote → ZygoteColorsExt\u001b[39m\n",
      "   2340.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCairo_jll\u001b[39m\n",
      "   1505.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mHarfBuzz_jll\u001b[39m\n",
      "   1336.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibass_jll\u001b[39m\n",
      "   1427.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPango_jll\u001b[39m\n",
      "   5030.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mJSON\u001b[39m\n",
      "   2318.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFFMPEG_jll\u001b[39m\n",
      "   1400.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFFMPEG\u001b[39m\n",
      "   3751.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGR_jll\u001b[39m\n",
      "   4936.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGR\u001b[39m\n",
      "  47962.3 ms\u001b[32m  ✓ \u001b[39mPlots\n",
      "  14 dependencies successfully precompiled in 75 seconds. 282 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(mktempdir())\n",
    "Pkg.update()\n",
    "Pkg.add([\n",
    "    \"Flux\",\n",
    "    \"LinearAlgebra\",\n",
    "    \"Statistics\",\n",
    "    \"Plots\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48a0a5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STABILITY COMPARISON: Random vs Doubly Stchastic\n",
      "============================================================\n",
      "\n",
      "--- unconstrained (HC-style) ---\n",
      "Single layer gain: forward=4.58, backward=4.06\n",
      "30-layer composite: forward=1.1157204e9, backward=2.802629e9\n",
      "\n",
      "--- Doubly stochastic (mHC-style) ---\n",
      "Single layer gain: forward=1.0, backward=1.0\n",
      "30-layer composite: forward=1.0, backward=1.0\n",
      "\n",
      "--- Verifying doubly stochastic property ---\n",
      "Row sums: Float32[1.0, 1.0, 1.0, 1.0]\n",
      "Col sums: Float32[1.0, 1.0, 1.0, 1.0]\n",
      "All non-negative: true\n",
      "Doubly stochastic: true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Matrix{Float32}[[0.11284312 0.34406877 -0.68308604 0.61050475; 0.69754755 -0.94521415 0.7930082 -1.330823; 1.8120838 -1.6061634 -0.62386453 0.5416502; 1.0643485 -1.1655983 1.5447383 -0.6329996], [-0.45682418 1.6256608 -0.7404751 -0.4840161; -1.7511808 -0.69520056 -2.6625447 1.015289; -0.83744967 -0.09121479 -0.16222441 0.39838046; -0.7068127 0.13429482 -0.554819 -0.46567833], [-2.2253518 0.67969984 0.7834992 0.50639355; 1.614896 0.27227393 -1.2053431 1.6054468; 0.9186541 -1.7763978 -0.26800478 0.17776069; 1.2163626 0.22726877 0.48391786 1.9790481], [-1.5200093 0.9575117 1.4383426 0.97984815; -1.9807007 1.9034126 0.70416915 0.9489625; 0.20598412 -0.8418422 -1.0052196 -0.66530526; 1.9061929 0.73347324 2.4500709 -0.14837994], [-0.77188253 1.4073231 -1.702729 -0.0060323817; -0.5140237 1.0368892 0.055263437 0.868878; 0.5888396 0.39154175 0.9200625 -0.1971379; 1.8708401 1.4196786 0.7532068 -1.695753], [-0.41828302 -0.67458814 0.7085174 0.34073806; -1.5079988 -2.8482811 1.1855991 -1.4713229; -1.5537444 0.8998862 -0.0835507 -0.22005409; 0.40543935 0.63249505 0.36187664 0.11911318], [1.9803544 0.86392784 0.37109196 1.1473446; 0.5784263 -0.12883815 0.12054478 1.1845815; 0.39891204 -0.25769258 0.19883579 -2.213929; -1.4225435 -0.5850762 0.9208264 -0.14065702], [0.53362197 -0.27405694 -0.12644467 -0.9404777; -0.8196297 -2.1559682 1.4098338 0.5055194; 0.5532479 0.56308234 -0.28120887 -0.12815835; 0.5534755 -0.9627346 -0.64991456 0.9919495], [-0.54961014 -0.43450475 0.70983666 -0.46106264; -0.18151116 -0.7950352 -0.31969061 -1.3892989; 2.0848575 -0.21890412 0.47426713 0.22325183; 0.45678386 2.311509 2.423427 0.5838705], [-0.46409032 -2.2633765 0.12053287 -0.10130884; 0.5907435 -2.4107416 0.94956845 1.5799979; -1.7078049 0.27182838 0.88964087 -1.2902699; -0.37163913 0.13319202 1.5052986 -0.7523117]  …  [-0.16029152 1.5664448 0.5455558 0.45556483; 0.8595826 -0.13895188 1.7813967 0.22090504; 0.19203001 0.4660376 -1.727242 0.28324595; 0.789563 1.2896856 -0.33762494 0.3848273], [0.089005716 1.2578346 0.65603554 -1.8994972; 0.30669722 1.0235102 -2.360036 -0.5259922; -1.122974 1.2922088 1.652014 1.6823506; 0.965798 -0.5605425 -1.0898407 -0.519985], [1.2956127 1.3166423 -0.5656299 -0.7308502; -1.6405971 0.20057192 -0.8986415 -0.15034644; 1.3220568 -0.40245026 0.39280924 1.022867; 0.8683888 -0.5025171 -0.2688393 -0.07154182], [-0.5239095 0.39768702 1.8017077 -1.3554778; -0.25598136 0.3243508 1.5237862 1.6183487; -1.0316434 -1.2958081 1.1684018 1.0414133; 0.73499423 0.29642674 -0.06438527 1.1734097], [-0.6617316 0.26517043 -0.8581412 -1.4877032; 1.7671943 -0.85631734 -0.896348 -1.6597415; 0.2811904 1.9139612 0.19481008 1.4341923; 0.73149014 -0.20133816 1.2397366 0.9290113], [-0.8277813 0.5709453 -1.8599893 0.8859968; 0.5966017 0.5389501 -2.063897 -1.8573245; 0.21282454 -0.028120292 -0.6038086 1.5432935; -0.5705552 0.50652957 -0.003434463 0.5864168], [1.3523183 0.5960194 -0.25821233 -0.66498893; 0.40373826 -0.6690549 -1.607849 1.6501297; -1.354276 -1.8825576 -0.50422275 0.72168237; -0.25777453 -0.09468486 -0.47224984 0.63259876], [1.7382606 -0.6645968 -1.5459635 0.3228353; 0.6543462 -0.41421375 -1.6425118 1.1765542; 0.009368002 1.585915 0.9764251 1.420027; 0.20967634 0.76337236 0.11462735 0.83779097], [-0.13300155 -0.65611094 0.47121683 -0.3678253; 1.731665 0.0837031 -0.63634664 -1.0735509; -0.65202206 -1.01017 0.38267073 -2.4802105; 0.34220874 1.1812958 -0.21297278 -1.4109347], [-1.2733796 0.8877326 0.20691967 1.1154016; -0.4213968 -1.3033108 -0.5091991 -1.6397429; 1.9496479 -1.0177544 -0.67532706 -0.44399044; 1.3867948 -0.40434098 1.8527128 -0.5581236]], Matrix{Float32}[[0.18951553 0.061425105 0.087048486 0.6620109; 0.03616269 0.1746675 0.5838262 0.20534365; 0.53325135 0.19571689 0.20225015 0.06878158; 0.24107045 0.5681905 0.12687525 0.063863866], [0.07565016 0.62543046 0.25582778 0.043091618; 0.29438785 0.054709643 0.38148972 0.26941282; 0.11023085 0.1362377 0.24093857 0.51259285; 0.51973116 0.1836222 0.1217439 0.17490272], [0.21085781 0.47463155 0.099415585 0.21509509; 0.072167076 0.12254135 0.48206967 0.3232219; 0.54411334 0.24624139 0.08375105 0.12589426; 0.17286184 0.15658568 0.3347637 0.3357888], [0.38152406 0.15248229 0.23802085 0.2279728; 0.10298184 0.059591744 0.38022992 0.4571965; 0.26430535 0.29686925 0.3240566 0.11476879; 0.25118873 0.4910567 0.057692662 0.20006189], [0.18403985 0.44646525 0.11046977 0.25902516; 0.32216206 0.28879106 0.055192675 0.33385423; 0.3152277 0.11418494 0.3939488 0.17663859; 0.17857037 0.15055878 0.4403888 0.23048204], [0.2452075 0.40260914 0.19537006 0.15681328; 0.15588732 0.3484871 0.26103312 0.2345925; 0.5017414 0.16705476 0.26249918 0.068704754; 0.097163826 0.081849016 0.2810977 0.53988945], [0.22966808 0.03306367 0.6793122 0.057956036; 0.2425071 0.12074743 0.13943599 0.49730948; 0.31169748 0.4192314 0.050143205 0.21892789; 0.21612735 0.42695746 0.13110861 0.22580661], [0.2674499 0.20969985 0.17686501 0.3459853; 0.47863406 0.021122491 0.17665914 0.32358432; 0.15851992 0.5310624 0.060730286 0.24968739; 0.09539608 0.23811528 0.58574563 0.080743045], [0.24716844 0.31295285 0.22089167 0.21898706; 0.3435279 0.26665416 0.36305326 0.026764676; 0.12569636 0.13469148 0.25227243 0.4873398; 0.28360733 0.2857015 0.16378269 0.2669085], [0.09936498 0.15336378 0.35175806 0.3955132; 0.24713165 0.36022437 0.20624733 0.18639666; 0.5061979 0.3284762 0.07529503 0.09003083; 0.14730541 0.15793568 0.3666996 0.32805932]  …  [0.30176297 0.4934735 0.076976925 0.12778662; 0.32221258 0.19126248 0.21682449 0.26970047; 0.054687705 0.21245924 0.5073512 0.22550185; 0.32133678 0.10280476 0.19884738 0.3770111], [0.4480818 0.20398866 0.16193946 0.1859901; 0.1234599 0.17152543 0.5324087 0.17260599; 0.31924352 0.07798346 0.05597494 0.5467981; 0.109214775 0.5465025 0.24967687 0.094605856], [0.044052925 0.13229293 0.48963836 0.33401582; 0.41309398 0.05790388 0.27946433 0.24953781; 0.30486408 0.19171333 0.17871611 0.3247065; 0.23798901 0.61808985 0.0521812 0.09173993], [0.4344802 0.066573344 0.35391545 0.145031; 0.16231443 0.15417857 0.36336696 0.32014; 0.046273317 0.5530904 0.1717695 0.22886682; 0.35693198 0.22615772 0.11094814 0.3059622], [0.2149483 0.1657589 0.3795112 0.23978168; 0.3107719 0.16381153 0.07066476 0.45475176; 0.2302403 0.066606805 0.52429277 0.17886011; 0.24403949 0.60382277 0.02553133 0.12660639], [0.24691848 0.22811049 0.4487342 0.07623686; 0.40607217 0.0510857 0.06769776 0.4751444; 0.07311847 0.51065856 0.14577442 0.27044857; 0.27389088 0.21014531 0.33779362 0.17817017], [0.31685266 0.021157594 0.10467261 0.5573172; 0.20808695 0.38552123 0.21226855 0.1941233; 0.022988126 0.40597308 0.3787164 0.19232243; 0.45207223 0.18734817 0.30434248 0.056237124], [0.13941795 0.26215234 0.05641448 0.54201525; 0.13868162 0.08286296 0.44366413 0.33479133; 0.27301311 0.61046785 0.05208061 0.064438425; 0.44888738 0.04451685 0.4478408 0.05875499], [0.5420756 0.3219401 0.081950955 0.054033373; 0.22362976 0.4436682 0.29125533 0.04144672; 0.10129486 0.13130672 0.24388123 0.5235172; 0.13299978 0.10308498 0.38291243 0.38100275], [0.24525651 0.18233618 0.4643176 0.10808968; 0.07697361 0.47739276 0.08803425 0.35759944; 0.43628255 0.17737117 0.10119483 0.28515148; 0.24148737 0.16289991 0.34645334 0.2491594]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Flux\n",
    "using LinearAlgebra\n",
    "using Statistics\n",
    "\n",
    "# =============================================================================\n",
    "# PART A: Core Building Blocks for Manifold-Constrained Hyper-Connections\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. SINKHORN-KNOPP ALGORITHM\n",
    "# Projects a matrix onto the Birkhoff polytope (doubly stochastic matrices)\n",
    "# \n",
    "# Mathematical intuition:\n",
    "# - Start with exp(M) to ensure positivity\n",
    "# - Alternately normalise rows and columns\n",
    "# - Converges to matrix where all rows AND columns sum to 1\n",
    "# - This is an entropy-regularised optimal transport projection\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "function sinkhorn_knopp(M::AbstractMatrix; max_iters::Int=20, ϵ::Float32=1f-8)\n",
    "    # Step 1: Make all entries positive via exponentiation\n",
    "    # This maps ℝ → ℝ⁺, preserving differentiability\n",
    "    P = exp.(M)\n",
    "\n",
    "    # Step 2: Alternating normalisation\n",
    "    # T_r: divide each row by its sum\n",
    "    # T_c: divide each column by its sum\n",
    "    for _ in 1:max_iters\n",
    "        # Row normalisation: each row sums to 1\n",
    "        P = P ./ (sum(P, dims=2) .+ ϵ)\n",
    "        # Column normalisation: each column sums to 1\n",
    "        P = P ./ (sum(P, dims=1) .+ ϵ)\n",
    "    end\n",
    "\n",
    "    return P\n",
    "end\n",
    "\n",
    "# Verify doubly stochastic property\n",
    "function check_doubly_stochastic(M::AbstractMatrix; tol::Float64=1e-3)\n",
    "    row_sums = vec(sum(M, dims=2))\n",
    "    col_sums = vec(sum(M, dims=1))\n",
    "\n",
    "    row_ok = all(abs.(row_sums .- 1.0) .< tol)\n",
    "    col_ok = all(abs.(col_sums .- 1.0) .< tol)\n",
    "    non_neg = all(M .>= 0)\n",
    "\n",
    "    println(\"Row sums: \", round.(row_sums, digits=4))\n",
    "    println(\"Col sums: \", round.(col_sums, digits=4))\n",
    "    println(\"All non-negative: \", non_neg)\n",
    "    println(\"Doubly stochastic: \", row_ok && col_ok && non_neg)\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. STANDARD RESIDUAL CONNECTION (Baseline)\n",
    "# x_{l+1} = x_l + F(x_l)\n",
    "# \n",
    "# The identity mapping property: gradient flows directly through addition\n",
    "# ∂L/∂x_l = ∂L/∂x_{l+1} · (1 + ∂F/∂x_l)\n",
    "# Even if ∂F/∂x_l vanishes, gradient still flows through the \"1\"\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "struct ResidualBlock\n",
    "    layer::Any  # The residual function F\n",
    "end\n",
    "\n",
    "Flux.@layer ResidualBlock\n",
    "\n",
    "function (rb::ResidualBlock)(x)\n",
    "    return x .+ rb.layer(x)\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. HYPER-CONNECTIONS (HC) LAYER\n",
    "# Expands residual stream width by factor n\n",
    "# \n",
    "# x_{l+1} = H_res · x_l + H_post^T · F(H_pre · x_l)\n",
    "#\n",
    "# Where:\n",
    "# - x_l ∈ ℝ^{n×C} is the expanded hidden state (n streams of C features)\n",
    "# - H_pre ∈ ℝ^{1×n} aggregates n streams → 1 stream for layer input\n",
    "# - H_post ∈ ℝ^{1×n} distributes layer output → n streams\n",
    "# - H_res ∈ ℝ^{n×n} mixes information between streams\n",
    "#\n",
    "# Problem: H_res is unconstrained → eigenvalues can be >1 or <1\n",
    "# Across many layers: ∏ H_res_i explodes or vanishes\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "struct HyperConnectionLayer\n",
    "    n::Int          # Expansion factor (number of streams)\n",
    "    C::Int          # Feature dimension per stream\n",
    "    layer::Any      # The actual computation (attention, MLP, etc.)\n",
    "\n",
    "    # Learnable parameters for dynamic mappings\n",
    "    ϕ_pre::Any      # Projects flattened input to H_pre\n",
    "    ϕ_post::Any     # Projects flattened input to H_post\n",
    "    ϕ_res::Any      # Projects flattened input to H_res\n",
    "\n",
    "    # Static bias terms\n",
    "    b_pre::Any\n",
    "    b_post::Any\n",
    "    b_res::Any\n",
    "\n",
    "    # Gating factors (initialised small for stability)\n",
    "    α_pre::Any\n",
    "    α_post::Any\n",
    "    α_res::Any\n",
    "end\n",
    "\n",
    "Flux.@layer HyperConnectionLayer\n",
    "\n",
    "function HyperConnectionLayer(n::Int, C::Int, layer; α_init::Float32=0.01f0)\n",
    "    nC = n * C # Flattened dimension\n",
    "\n",
    "    HyperConnectionLayer(\n",
    "        n, C, layer,\n",
    "        Dense(nC => n),             # ϕ_pre: ℝ^{nC} → ℝ^n\n",
    "        Dense(nC => n),             # ϕ_post: ℝ^{nC} → ℝ^n\n",
    "        Dense(nC => n*n),             # ϕ_res: ℝ^{nC} → ℝ^{n²}\n",
    "        zeros(Float32, 1, n),       # b_pre\n",
    "        zeros(Float32, 1, n),       # b_post\n",
    "        zeros(Float32, 1, n),       # b_res (initialise to identity-like)\n",
    "        [α_init],                   # α_pre\n",
    "        [α_init],                   # α_post\n",
    "        [α_init]                    # α_res\n",
    "    )\n",
    "end\n",
    "\n",
    "function (hc::HyperConnectionLayer)(x_expanded)\n",
    "    # x_expanded: (n, C, batch) - n streams of C features\n",
    "    n, C, batch = size(x_expanded)\n",
    "\n",
    "    # Flatten for computing dynamic mappings: (nC, batch)\n",
    "    x_flat = reshape(x_expanded, n * C, batch)\n",
    "\n",
    "    # Compute dynamic mappings (simplified - full version uses RMSNorm)\n",
    "    H_pre = hc.α_pre[1] .* hc.ϕ_pre(x_flat)' .+ hc.b_pre # (batch, n)\n",
    "    H_post = hc.α_post[1] .* hc.ϕ_post(x_flat)' .+ hc.b_post # (batch, n)\n",
    "\n",
    "    # H_res needs reshaping: (n, n) per batch element\n",
    "    H_res_flat = hc.α_res[1] .* hc.ϕ_res(x_flat)    # (n², batch)\n",
    "\n",
    "    # For simplicity, use batch-averaged H_res (full impl is per-sample)\n",
    "    H_res_mean = reshape(mean(H_res_flat, dims=2), n, n) .+ hc.b_res .+ I(n)\n",
    "\n",
    "    # === KEY ISSUE: H_res is UNCONSTRAINED ===\n",
    "    # Eigenvalues can be anything → instability across layers\n",
    "\n",
    "    # Pre-mapping: aggregate n streams to 1 for layer input\n",
    "    # h_in = H_pre ⋅ x_expanded → (C, batch)\n",
    "    h_in = zeros(Float32, C, batch)\n",
    "    for b in 1:batch\n",
    "        h_in[:, b] = sum(H_pre[b, 1] .* x_expanded[i, :, b] for i in 1:n)\n",
    "    end\n",
    "\n",
    "    # Apply the actual layer F\n",
    "    h_out = hc.layer(h_in) # (C, batch)\n",
    "\n",
    "    # Post-mapping: distribute output to n streams\n",
    "    # Residual mapping: mix existing streams\n",
    "    x_next = similar(x_expanded)\n",
    "    for b in 1:batch\n",
    "        # Residual: H_res ⋅ x_l\n",
    "        for i in 1:n\n",
    "            x_next[i, :, b] = sum(H_res_mean[i, j] .* x_expanded[j, :, b] for j in 1:n)\n",
    "        end\n",
    "\n",
    "        # Add post-mapped layer output\n",
    "        for i in 1:n\n",
    "            x_next[i, :, b] .+= H_post[b, i] .* h_out[:, b]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return x_next\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. MANIFOLD-CONSTRAINED HYPER-CONNECTIONS (mHC)\n",
    "# Same structure as HC, but H_res is projected onto Birkhoff polytope\n",
    "#\n",
    "# Key changes:\n",
    "# - H_res = Sinkhorn-Knopp(H̃_res) → doubly stochastic\n",
    "# - H_pre = σ(H̃_pre) → non-negative (prevents signal cancellation)\n",
    "# - H_post = 2σ(H̃_post) → non-negative, scaled\n",
    "#\n",
    "# Why doubly stochastic works:\n",
    "# 1. Spectral norm ≤ 1: ||H_res||_2 ≤ 1 → non-expansive\n",
    "# 2. Closure: product of doubly stochastic is doubly stochastic\n",
    "# 3. Convex combination: H_res · x is weighted average of streams\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "struct ManifoldHCLayer\n",
    "    n::Int\n",
    "    C::Int\n",
    "    layer::Any\n",
    "\n",
    "    ϕ_pre::Any\n",
    "    ϕ_post::Any\n",
    "    ϕ_res::Any\n",
    "\n",
    "    b_pre::Any\n",
    "    b_post::Any\n",
    "    b_res::Any\n",
    "\n",
    "    α_pre::Any\n",
    "    α_post::Any\n",
    "    α_res::Any\n",
    "    \n",
    "    sk_iters::Int # Sinkhorn-Knopp iterations\n",
    "end\n",
    "\n",
    "Flux.@layer ManifoldHCLayer\n",
    "\n",
    "function ManifoldHCLayer(n::Int, C::Int, layer; α_init::Float32=0.01f0, sk_iters::Int=20)\n",
    "    nC = n * C\n",
    "\n",
    "    ManifoldHCLayer(\n",
    "        n, C, layer,\n",
    "        Dense(nC => n),\n",
    "        Dense(nC => n),\n",
    "        Dense(nC => n*n),\n",
    "        zeros(Float32, 1, n),\n",
    "        zeros(Float32, 1, n),\n",
    "        zeros(Float32, 1, n),\n",
    "        [α_init],\n",
    "        [α_init],\n",
    "        [α_init],\n",
    "        sk_iters\n",
    "    )\n",
    "end\n",
    "\n",
    "function (mhc::ManifoldHCLayer)(x_expanded)\n",
    "    n, C, batch = size(x_expanded)\n",
    "\n",
    "    x_flat = reshape(x_expanded, n * C, batch)\n",
    "\n",
    "    # Compute raw mappings\n",
    "    H_pre_raw = mhc.α_pre[1] .* mhc.ϕ_pre(x_flat)' .+ mhc.b_pre\n",
    "    H_post_raw = mhc.α_post[1] .* mhc.ϕ_post(x_flat)' .+ mhc.b_post\n",
    "    H_res_flat = mhc.α_res[1] .* mhc.ϕ_res(x_flat)\n",
    "\n",
    "    # === KEY DIFFERENCE: Apply manifold constraints ===\n",
    "\n",
    "    # Non-negativity fro pre/post via sigmoid\n",
    "    H_pre = sigmoid.(H_pre_raw)     # ∈ [0,1]\n",
    "    H_post = 2f0 .* sigmoid.(H_post_raw)    # ∈ [0,2] for expressivity\n",
    "\n",
    "    # Doubly stochastic constraint for residual via Sinkhorn-Knopp\n",
    "    H_res_mean = reshape(mean(H_res_flat, dims=2), n, n) .+ mhc.b_res\n",
    "    H_res = sinkhorn_knopp(H_res_mean; max_iters=mhc.sk_iters)\n",
    "\n",
    "    # Now H_res has:\n",
    "    # - All entries ≥ 0\n",
    "    # - Each row sums to 1 → output is convex combination\n",
    "    # - Each column sums to 1 → gradients are bounded\n",
    "    # - Spectral norm ≤ 1 → non-expansive\n",
    "\n",
    "    # Pre-mapping with constrained coefficients\n",
    "    h_in = zeros(Float32, C, batch)\n",
    "    for b in 1:batch\n",
    "        h_in[:, b] = sum(H_pre[b, i] .* x_expanded[i, :, b] for i in 1:n)\n",
    "    end\n",
    "\n",
    "    h_out = mhc.layer(h_in)\n",
    "\n",
    "    # Residual and post-mapping with constrained matrices\n",
    "    x_next = similar(x_expanded)\n",
    "    for b in 1:batch\n",
    "        for i in 1:n\n",
    "            # Constrained residual mixing\n",
    "            x_next[i, :, b] = sum(H_res[i, j] .* x_expanded[j, :, b] for j in 1:n)\n",
    "        end\n",
    "        for i in 1:n\n",
    "            x_next[i, :, b] .+= H_post[b, i] .* h_out[:, b]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return x_next\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. UTILITY: Measure Signal/Gradient Gain\n",
    "# This is what the paper measures in Fig. 3 and Fig. 7\n",
    "#\n",
    "# Forward signal gain: max row sum of H_res (how much signal amplifies)\n",
    "# Backward gradient gain: max column sum (how much gradient amplifies)\n",
    "#\n",
    "# For stable training, both should be close to 1\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "function measure_gain(H::AbstractMatrix)\n",
    "    # Forward: signal x → H⋅x, gain is max row sum\n",
    "    forward_gain = maximum(sum(abs.(H), dims=2))\n",
    "\n",
    "    # Backward: gradient g → H^T⋅g, gain is max column sum\n",
    "    backward_gain = maximum(sum(abs.(H), dims=1))\n",
    "\n",
    "    return (forward=forward_gain, backward=backward_gain)\n",
    "end\n",
    "\n",
    "function mesaure_composite_gain(matrices::Vector{<:AbstractMatrix})\n",
    "    # Composite mapping across layers: Π H_i\n",
    "    composite = matrices[1]\n",
    "    for i in 2:length(matrices)\n",
    "        composite = matrices[i] * composite\n",
    "    end\n",
    "    return measure_gain(composite)\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. DEMONSTRATION: Compare stability of random vs doubly stochastic\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "function demo_stability_comparison()\n",
    "    println(\"\\n\" * \"=\"^60)\n",
    "    println(\"STABILITY COMPARISON: Random vs Doubly Stchastic\")\n",
    "    println(\"=\"^60)\n",
    "\n",
    "    n = 4 # Expansion factor\n",
    "    num_layers = 30\n",
    "\n",
    "    # Generate random unconstrained matrices (like HC)\n",
    "    println(\"\\n--- unconstrained (HC-style) ---\")\n",
    "    hc_matrices = [randn(Float32, n, n) for _ in 1:num_layers]\n",
    "\n",
    "    # Check single layer\n",
    "    single_gain = measure_gain(hc_matrices[1])\n",
    "    println(\"Single layer gain: forward=$(round(single_gain.forward, digits=2)), backward=$(round(single_gain.backward, digits=2))\")\n",
    "\n",
    "    # Check composite\n",
    "    composite_gain = mesaure_composite_gain(hc_matrices)\n",
    "    println(\"30-layer composite: forward=$(round(composite_gain.forward, digits=2)), backward=$(round(composite_gain.backward, digits=2))\")\n",
    "\n",
    "    # Generate doubly stochastic matrices (like mHC)\n",
    "    println(\"\\n--- Doubly stochastic (mHC-style) ---\")\n",
    "    mhc_matrices = [sinkhorn_knopp(randn(Float32, n, n)) for _ in 1:num_layers]\n",
    "\n",
    "    single_gain = measure_gain(mhc_matrices[1])\n",
    "    println(\"Single layer gain: forward=$(round(single_gain.forward, digits=2)), backward=$(round(single_gain.backward, digits=2))\")\n",
    "\n",
    "    composite_gain = mesaure_composite_gain(mhc_matrices)\n",
    "    println(\"30-layer composite: forward=$(round(composite_gain.forward, digits=2)), backward=$(round(composite_gain.backward, digits=2))\")\n",
    "\n",
    "    # Verify doubly stochastic property\n",
    "    println(\"\\n--- Verifying doubly stochastic property ---\")\n",
    "    check_doubly_stochastic(mhc_matrices[1])\n",
    "\n",
    "    return hc_matrices, mhc_matrices\n",
    "end\n",
    "\n",
    "demo_stability_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c1a190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training comparison: Residual vs HC vs mHC\n",
      "============================================================\n",
      "Layers: 8, Hidden: 128, Expansion: 4\n",
      "Data shape: (64, 5000), (10, 5000)\n",
      "\n",
      "Creating models...\n",
      "ResidualMLP: 1065610 parameters\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `nC` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `nC` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      "  [1] HyperConnectionLayer(n::Int64, C::Int64, layer::Chain{Tuple{LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}; α_init::Float32)\n",
      "    @ Main c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W1sZmlsZQ==.jl:114\n",
      "  [2] HyperConnectionLayer(n::Int64, C::Int64, layer::Chain{Tuple{LayerNorm{typeof(identity), Flux.Scale{typeof(identity), Vector{Float32}, Vector{Float32}}, Float32, 1}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})\n",
      "    @ Main c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W1sZmlsZQ==.jl:111\n",
      "  [3] (::var\"#171#172\"{Int64, Int64, var\"#make_inner_mlp#170\"{Int64}})(::Int64)\n",
      "    @ Main .\\none:-1\n",
      "  [4] iterate\n",
      "    @ .\\generator.jl:48 [inlined]\n",
      "  [5] collect(itr::Base.Generator{UnitRange{Int64}, var\"#171#172\"{Int64, Int64, var\"#make_inner_mlp#170\"{Int64}}})\n",
      "    @ Base .\\array.jl:790\n",
      "  [6] HCMLP(input_dim::Int64, hidden_dim::Int64, output_dim::Int64, num_layers::Int64; n::Int64)\n",
      "    @ Main c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:75\n",
      "  [7] HCMLP\n",
      "    @ c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:67 [inlined]\n",
      "  [8] create_models(input_dim::Int64, hidden_dim::Int64, output_dim::Int64, num_layers::Int64; n::Int64)\n",
      "    @ Main c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:319\n",
      "  [9] create_models\n",
      "    @ c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:310 [inlined]\n",
      " [10] run_training_comparison(; input_dim::Int64, hidden_dim::Int64, output_dim::Int64, num_layers::Int64, n_samples::Int64, n_epochs::Int64, lr::Float64, expansion::Int64)\n",
      "    @ Main c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:356\n",
      " [11] run_training_comparison()\n",
      "    @ Main c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:335\n",
      " [12] top-level scope\n",
      "    @ c:\\Users\\79021\\OneDrive - РУТ (МИИТ)\\Рабочий стол\\Study\\ml_learn\\MCHC\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:391"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux: onehotbatch, onecold\n",
    "using Statistics\n",
    "using Random\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. STANDARD RESIDUAL MLP\n",
    "# Simple baseline: stack of residual blocks\n",
    "# x_{l+1} = x_l + MLP(x_l)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "struct ResidualMLP\n",
    "    input_proj::Any     # Project input to hidden dim\n",
    "    blocks::Any         # Vector or residual blocks\n",
    "    output_proj::Any    # Project to output classes\n",
    "    norm::Any           # Final normalisation\n",
    "end\n",
    "\n",
    "Flux.@layer ResidualMLP\n",
    "\n",
    "function ResidualMLP(input_dim::Int, hidden_dim::Int, output_dim::Int, num_layers::Int)\n",
    "    # Each residual block: LayerNorm → Dense → ReLU → Dense\n",
    "    make_block() = ResidualBlock(\n",
    "        Chain(\n",
    "            LayerNorm(hidden_dim),\n",
    "            Dense(hidden_dim => hidden_dim * 4, relu),\n",
    "            Dense(hidden_dim * 4 => hidden_dim)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ResidualMLP(\n",
    "        Dense(input_dim => hidden_dim),\n",
    "        [make_block() for _ in 1:num_layers],\n",
    "        Dense(hidden_dim => output_dim),\n",
    "        LayerNorm(hidden_dim)\n",
    "    )\n",
    "end\n",
    "\n",
    "function (m::ResidualMLP)(x)\n",
    "    # x: (input_dim, batch)\n",
    "    h = m.input_proj(x)\n",
    "\n",
    "    for block in m.blocks\n",
    "        h = block(h)\n",
    "    end\n",
    "\n",
    "    h = m.norm(h)\n",
    "    return m.output_proj(h)\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. HYPER-CONNECTIONS MLP\n",
    "# Expands residual stream by factor n\n",
    "# Demonstrates the instability problem\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "struct HCMLP\n",
    "    n::Int      # Expansion factor\n",
    "    input_proj::Any     # Project to expanded hidden state\n",
    "    blocks::Any         # Vector of HC layers\n",
    "    output_proj::Any    # Collapse and project to output\n",
    "    norm::Any\n",
    "end\n",
    "\n",
    "Flux.@layer HCMLP\n",
    "\n",
    "function HCMLP(input_dim::Int, hidden_dim::Int, output_dim::Int, num_layers::Int; n::Int=4)\n",
    "    # Inner MLP for each HC layer\n",
    "    make_inner_mlp() = Chain(\n",
    "        LayerNorm(hidden_dim),\n",
    "        Dense(hidden_dim => hidden_dim * 4, relu),\n",
    "        Dense(hidden_dim * 4 => hidden_dim)\n",
    "    )\n",
    "\n",
    "    HCMLP(\n",
    "        n,\n",
    "        Dense(input_dim => hidden_dim * n),     # Expand to n streams\n",
    "        [HyperConnectionLayer(n, hidden_dim, make_inner_mlp()) for _ in 1:num_layers],\n",
    "        Chain(\n",
    "            x -> mean(x, dims=1)[1, :, :],      # Average across streams\n",
    "            LayerNorm(hidden_dim),\n",
    "            Dense(hidden_dim => output_dim)\n",
    "        ),\n",
    "        LayerNorm(hidden_dim)\n",
    "    )\n",
    "end\n",
    "\n",
    "function (m::HCMLP)(x)\n",
    "    batch = size(x, 2)\n",
    "\n",
    "    # Project and reshape to (n, C, batch)\n",
    "    h_flat = m.input_proj(x)    # (n*C, batch)\n",
    "    h = reshape(h_flat, m.n, size(h_flat, 1) ÷ m.n, batch)\n",
    "\n",
    "    for block in m.blocks\n",
    "        h = block(h)\n",
    "    end\n",
    "\n",
    "    return m.output_proj(h)\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. MANIFOLD-CONSTRAINED HC MLP\n",
    "# Same structure as HC but with stability guarantees\n",
    "# This is the main contribution of the mHC paper\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "struct mHCMLP\n",
    "    n::Int\n",
    "    input_proj::Any\n",
    "    blocks::Any\n",
    "    output_proj::Any\n",
    "    norm::Any\n",
    "end\n",
    "\n",
    "Flux.@layer mHCMLP\n",
    "\n",
    "function mHCMLP(input_dim::Int, hidden_dim::Int, output_dim::Int, num_layers::Int;\n",
    "    n::Int=4, sk_iters::Int=20)\n",
    "    make_inner_mlp() = Chain(\n",
    "        LayerNorm(hidden_dim),\n",
    "        Dense(hidden_dim => hidden_dim * 4, relu),\n",
    "        Dense(hidden_dim * 4 => hidden_dim)\n",
    "    )\n",
    "\n",
    "    mHCMLP(\n",
    "        n,\n",
    "        Dense(input_dim => hidden_dim * n),\n",
    "        [ManifoldHCLayer(n, hidden_dim, make_inner_mlp(); sk_iters=sk_iters) for _ in 1:num_layers],\n",
    "        Chain(\n",
    "            x -> mean(x, dims=1)[1, :, :],\n",
    "            LayerNorm(hidden_dim),\n",
    "            Dense(hidden_dim => output_dim)\n",
    "        ),\n",
    "        LayerNorm(hidden_dim)\n",
    "    )\n",
    "end\n",
    "\n",
    "function (m::mHCMLP)(x)\n",
    "    batch = size(x, 2)\n",
    "\n",
    "    h_flat = m.input_proj(x)\n",
    "    h = reshape(h_flat, m.n, size(h_flat, 1) ÷ m.n, batch)\n",
    "\n",
    "    for block in m.blocks\n",
    "        h = block(h)\n",
    "    end\n",
    "\n",
    "    return m.output_proj(h)\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. TRAINING UTILITIES\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Cross-entropy loss with softmax\n",
    "function ce_loss(model, x, y)\n",
    "    logits = model(x)\n",
    "    return Flux.logitcrossentropy(logits, y)\n",
    "end\n",
    "\n",
    "# Accurocy computation\n",
    "function accuracy(model, x, y)\n",
    "    logits = model(x)\n",
    "    preds = onecold(logits)\n",
    "    targets = onecold(y)\n",
    "    return mean(preds .== targets)\n",
    "end\n",
    "\n",
    "# Gradient norm for monitoring stability\n",
    "function compute_grad_norm(grads)\n",
    "    total = 0.0f0\n",
    "    for (_, g) in pairs(grads)\n",
    "        if g !== nothing\n",
    "            if g isa AbstractArray\n",
    "                total += sum(abs2, g)\n",
    "            elseif g isa NamedTuple || g isa Tuple\n",
    "                total += compute_grad_norm(g)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return sqrt(total)\n",
    "end\n",
    "\n",
    "# Extract H_res matrices for analysis\n",
    "function extract_hres_matrices(model::mHCMLP)\n",
    "    matrices = Matrix{Float32}[]\n",
    "    for block in model.blocks\n",
    "        # Compute H_res for a dummy input\n",
    "        n, C = block.n, block.C\n",
    "        dummy = zeros(Float32, n * C, 1)\n",
    "        H_res_flat = block.α_res[1] * block.ϕ_res(dummy)\n",
    "        H_res_raw = reshape(H_res_flat, n, n) .+ block.b_res\n",
    "        H_res = sinkhorn_knopp(H_res_raw; max_iters=block.sk_iters)\n",
    "        push!(matrices, H_res)\n",
    "    end\n",
    "    return matrices\n",
    "end\n",
    "\n",
    "function extract_hres_matrices(model::HCMLP)\n",
    "    matrices = Matrix{Float32}[]\n",
    "    for block in model.blocks\n",
    "        n, C = block.n, block.C\n",
    "        dummy = zeros(Float32, n * C, 1)\n",
    "        H_res_flat = block.α_res[1] .* block.ϕ_res(dummy)\n",
    "        H_res = reshape(H_res_flat, n, n) .+ block.b_res .+ I(n)\n",
    "        push!(matrices, H_res)\n",
    "    end\n",
    "    return matrices\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. TRAINING LOOP WITH METRICS COLLECTION\n",
    "# Returns history for plotting\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "struct TrainingHistory\n",
    "    losses::Vector{Float32}\n",
    "    accuracies::Vector{Float32}\n",
    "    grad_norms::Vector{Float32}\n",
    "    forward_gains::Vector{Float32}  # Signal propagation stability\n",
    "    backward_gains::Vector{Float32} # Gradient propagation stability\n",
    "end\n",
    "\n",
    "TrainingHistory() = TrainingHistory(\n",
    "    Float32[], Float32[], Float32[], Float32[], Float32[]\n",
    ")\n",
    "\n",
    "function train_epoch!(model, opt_state, train_x, train_y, history::TrainingHistory)\n",
    "    batch_size = 64\n",
    "    n_samples = size(train_x, 2)\n",
    "    n_batches = n_samples ÷ batch_size\n",
    "\n",
    "    epoch_loss = 0.0f0\n",
    "    epoch_grad_norm = 0.0f0\n",
    "\n",
    "    for i in 1:n_batches\n",
    "        idx = ((i-1)*batch_size + 1):(i*batch_size)\n",
    "        x_batch = train_x[:, idx]\n",
    "        y_batch = train_y[:, idx]\n",
    "\n",
    "        # Compute loss and gradients\n",
    "        loss, grads = Flux.withgradient(model) do m\n",
    "            ce_loss(m, x_batch, y_batch)\n",
    "        end\n",
    "\n",
    "        # Update parameters\n",
    "        Flux.update!(opt_state, model, grads[1])\n",
    "\n",
    "        epoch_loss += loss\n",
    "        epoch_grad_norm += compute_grad_norm(grads[1])\n",
    "    end\n",
    "\n",
    "    # Record metrics\n",
    "    push!(history.losses, epoch_loss / n_batches)\n",
    "    push!(history.grad_norms, epoch_grad_norm / n_batches)\n",
    "\n",
    "    # Compute propagation stability (if HC or mHC)\n",
    "    if model isa HCMLP || model isa mHCMLP\n",
    "        matrices = extract_hres_matrices(model)\n",
    "        if !isempty(matrices)\n",
    "            composite_gain = measure_composite_gain(matrices)\n",
    "            push!(history.forward_gains, composite_gain.forward)\n",
    "            push!(history.backward_gains, composite_gain.backward)\n",
    "        end\n",
    "    else\n",
    "        # For standard residual, gain is always 1\n",
    "        push!(history.forward_gains, 1.0f0)\n",
    "        push!(history.backward_gains, 1.0f0)\n",
    "    end\n",
    "\n",
    "    return history\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. SYNTHETIC DATASET GENERATOR\n",
    "# For controlled experiments\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "function generate_synthetic_data(n_samples::Int, input_dim::Int, n_classes::Int; seed::Int=42)\n",
    "    Random.seed!(seed)\n",
    "\n",
    "    # Generate cluster centers\n",
    "    centers = randn(Float32, input_dim, n_classes) .* 3\n",
    "\n",
    "    # Generate samples around centers\n",
    "    samples_per_class = n_samples ÷ n_classes\n",
    "\n",
    "    X = zeros(Float32, input_dim, n_samples)\n",
    "    Y = zeros(Float32, n_classes, n_samples)\n",
    "\n",
    "    for c in 1:n_classes\n",
    "        idx_start = (c-1) * samples_per_class + 1\n",
    "        idx_end = c * samples_per_class\n",
    "\n",
    "        X[:, idx_start:idx_end] = centers[:, c] .+ randn(Float32, input_dim, samples_per_class) .* 0.5\n",
    "        Y[c, idx_start:idx_end] .= 1.0f0\n",
    "    end\n",
    "\n",
    "    # Shuffle\n",
    "    perm = randperm(n_samples)\n",
    "    return X[:, perm], Y[:, perm]\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7. MODEL FACTORY\n",
    "# Creates models with comparable parameter counts\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "function create_models(input_dim::Int, hidden_dim::Int, output_dim::Int, num_layers::Int; n::Int=4)\n",
    "    println(\"\\nCreating models...\")\n",
    "\n",
    "    # Standard residual\n",
    "    residual = ResidualMLP(input_dim, hidden_dim, output_dim, num_layers)\n",
    "    n_params_res = sum(length, Flux.params(residual))\n",
    "    println(\"ResidualMLP: $(n_params_res) parameters\")\n",
    "\n",
    "    # Hyper-CONNECTIONS\n",
    "    hc = HCMLP(input_dim, hidden_dim, output_dim, num_layers; n=n)\n",
    "    n_params_hc = sum(length, Flux.params(hc))\n",
    "    println(\"HCMLP: $(n_params_hc) parameters\")\n",
    "\n",
    "    # Manifold-Contrained HC\n",
    "    mhc = mHCMLP(input_dim, hidden_dim, output_dim, num_layers; n=n)\n",
    "    n_params_mhc = sum(length, Flux.params(mhc))\n",
    "    println(\"mHCMLP: $(n_params_mhc) parameters\")\n",
    "\n",
    "    return residual, hc, mhc\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8. FULL TRAINING COMPARISON\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "function run_training_comparison(;\n",
    "    input_dim::Int=64,\n",
    "    hidden_dim::Int=128,\n",
    "    output_dim::Int=10,\n",
    "    num_layers::Int=8,\n",
    "    n_samples::Int=5000,\n",
    "    n_epochs::Int=30,\n",
    "    lr::Float64=1e-3,\n",
    "    expansion::Int=4\n",
    "    )\n",
    "\n",
    "    println(\"\\n\" * \"=\"^60)\n",
    "    println(\"Training comparison: Residual vs HC vs mHC\")\n",
    "    println(\"=\"^60)\n",
    "    println(\"Layers: $num_layers, Hidden: $hidden_dim, Expansion: $expansion\")\n",
    "\n",
    "    # Generate Data\n",
    "    train_x, train_y = generate_synthetic_data(n_samples, input_dim, output_dim)\n",
    "    println(\"Data shape: $(size(train_x)), $(size(train_y))\")\n",
    "\n",
    "    # Create models\n",
    "    residual, hc, mhc = create_models(input_dim, hidden_dim, output_dim, num_layers; n=expansion)\n",
    "\n",
    "    # Training histories\n",
    "    hist_res = TrainingHistory()\n",
    "    hist_hc = TrainingHistory()\n",
    "    hist_mhc = TrainingHistory()\n",
    "\n",
    "    # Optimisers\n",
    "    opt_res = Flux.setup(Adam(lr), residual)\n",
    "    opt_hc = Flux.setup(Adam(lr), hc)\n",
    "    opt_mhc = Flux.setup(Adam(lr), mhc)\n",
    "\n",
    "    println(\"\\nTraining...\")\n",
    "    for epoch in 1:n_epochs\n",
    "        train_epoch!(residual, opt_res, train_x, train_y, hist_res)\n",
    "        train_epoch!(hc, opt_hc, train_x, train_y, hist_hc)\n",
    "        train_epoch!(mhc, opt_mhc, train_x, train_y, hist_mhc)\n",
    "\n",
    "        if epoch % 5 == 0 || epoch == 1\n",
    "            println(\"Epoch $epoch:\")\n",
    "            println(\"   Residual - Loss: $(round(hist_res.losses[end], digits=4)), \n",
    "            Acc: $(round(hist_res.accuracies[end]*100, digits=1))%\")\n",
    "            println(\"   HC - Loss: $(round(hist_hc.losses[end], digits=4)), \n",
    "            Acc: $(round(hist_hc.accuracies[end]*100, digits=1))%\")\n",
    "            println(\"   mHC - Loss: $(round(hist_mhc.losses[end], digits=4)), \n",
    "            Acc: $(round(hist_mhc.accuracies[end]*100, digits=1))%\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return (\n",
    "        models = (residual=residual, hc=hc, mhc=mhc),\n",
    "        histories = (residual=hist_res, hc=hist_hc, mhc=hist_mhc)\n",
    "    )\n",
    "end\n",
    "\n",
    "run_training_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d090c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Statistics\n",
    "using Printf\n",
    "\n",
    "# =============================================================================\n",
    "# PART C: Experiments and Visualisation\n",
    "# Replicates key analyses from the mHC paper\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. EXPERIMENT: Matrix Propagation Stability\n",
    "# Demonstrates why doubly stochastic constraint matters\n",
    "# Similar to Fig. 3 vs Fig. 7 in the paper\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "function experiment_propagation_stability(; n::Int=4, num_layers::Int=60)\n",
    "    println(\"\\n\" * \"=\"^60)\n",
    "    println(\"Experiment 1: Propagation stability analysis\")\n",
    "    println(\"=\"^60)\n",
    "\n",
    "    # Generate unconstrained matrices (HC-style)\n",
    "    hc_matrices = [randn(Float32, n, n) .* 0.5f0 .+ I(n) for _ in 1:num_layers]\n",
    "\n",
    "    # Generated doubly stochastic matrices (mHC-style)\n",
    "    mhc_matrices = [sinkhorn_knopp(randn(Float32, n, n)) for _ in 1:num_layers]\n",
    "\n",
    "    # Compute gains at each layer depth\n",
    "    hc_forward = Float32[]\n",
    "    hc_backward = Float32[]\n",
    "    mhc_forward = Float32[]\n",
    "    mhc_backward = Float32[]\n",
    "\n",
    "    for l in 1:num_layers\n",
    "        # Composite mapping up to layer l\n",
    "        hc_composite = reduce(*, hc_matrices[1:l])\n",
    "        mhc_composite = reduce(*, mhc_matrices[1:l])\n",
    "\n",
    "        hc_gain = measure_gain(hc_composite)\n",
    "        mhc_gain = measure_gain(mhc_composite)\n",
    "\n",
    "        push!(hc_forward, hc_gain.forward)\n",
    "        push!(hc_backward, hc_gain.backward)\n",
    "        push!(mhc_forward, mhc_gain.forward)\n",
    "        push!(mhc_backward, mhc_gain.backward)\n",
    "    end\n",
    "\n",
    "    # Create Visualisation\n",
    "    p1 = plot(1:num_layers, hc_forward,\n",
    "        label=\"HC Forward\",\n",
    "        ylabel=\"Gain magnitude\",\n",
    "        xlabel=\"Layer Depth\",\n",
    "        title=\"Signal Propagation gain\",\n",
    "        yscale=:log10,\n",
    "        linewidth=2,\n",
    "        color=:red\n",
    "    )\n",
    "    plot!(p1, 1:num_layers, mhc_forward,\n",
    "        label=\"mHC Forward\",\n",
    "        linewidth=2,\n",
    "        color=:blue\n",
    "    )\n",
    "    hline!(p1, [0,0], label=\"Ideal (1.0)\", linestyle=:dash, color=:black)\n",
    "\n",
    "    p2 = plot(1:num_layers, hc_backward,\n",
    "        label=\"HC Backward\",\n",
    "        ylabel=\"Gain magnitude\",\n",
    "        xlabel=\"Layer depth\",\n",
    "        title=\"Gradient propagation gain\",\n",
    "        yscale=:log10,\n",
    "        linewidth=2,\n",
    "        color=:red\n",
    "    )\n",
    "    plot!(p2, 1:num_layers, mhc_backward,\n",
    "        label=\"mHC Backward\",\n",
    "        linewidth=2,\n",
    "        color=:blue\n",
    "    )\n",
    "    hline!(p2, [1.0], label=\"Idel (1.0)\", linestyle=:dash, color=:black)\n",
    "\n",
    "    p = plot(p1, p2, layout=(1, 2), size=(900, 400))\n",
    "    savefig(p, \"propagation_stability.png\")\n",
    "    println(\"Saved: propagation_stability.png\")\n",
    "\n",
    "    # Print summary Statistics\n",
    "    println(\"\\nFinal layer gains (layer $num_layers):\")\n",
    "    println(\"   HC - Forward: $(@sprintf(\"%.2e\", hc_forward[end])), \n",
    "    Backward: $(@sprintf(\"%.2e\", hc_backward[end]))\")\n",
    "    println(\"   mHC - Forward: $(@sprintf(\"%.4f\", mhc_forward[end])), \n",
    "    Backward: $(@sprintf(\"%.4f\", mhc_backward[end]))\")\n",
    "\n",
    "    return (hc=(forward=hc_forward, backward=hc_backward),\n",
    "            mhc=(forward=mhc_forward, backward=mhc_backward))\n",
    "end\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. EXPERIMENT: Training Dynamics Comparison\n",
    "# Compares loss curves, gradient norms, and stability metrics\n",
    "# Similar to Fig. 5 in the paper\n",
    "# -----------------------------------------------------------------------------\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.3",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
